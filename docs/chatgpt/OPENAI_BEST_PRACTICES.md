# EcoAgent ChatGPT Integration - OpenAI Best Practices Applied

**Reference**: https://developers.openai.com/blog/what-makes-a-great-chatgpt-app  
**Updated**: November 26, 2025  
**Status**: Fully aligned with OpenAI recommendations

---

## üìã Executive Summary

EcoAgent's ChatGPT integration has been refined to follow OpenAI's comprehensive best practices guide. This document outlines what was changed and why.

### Key Improvements

‚úÖ **Tool clarity**: Simplified names and descriptions  
‚úÖ **Value proposition**: Clear KNOW/DO/SHOW framework  
‚úÖ **User experience**: Better first-interaction handling  
‚úÖ **Model guidance**: Explicit tool-selection logic  
‚úÖ **Privacy**: Minimal data collection by design  
‚úÖ **Ecosystem fit**: Small, focused, composable actions  

---

## üéØ The Three Ways to Add Value (KNOW/DO/SHOW)

### 1. KNOW: New Environmental Context
**Principle**: ChatGPT can't see current environmental data or private information. EcoAgent bridges this gap.

**What Changed**:
- Tool: `calculate_carbon_footprint` (was: `get_carbon_footprint_calculation`)
- Description now includes: "Use this when users ask about their environmental impact from specific activities"
- Added clarity on what data is current/not in training

**Examples**:
- "How much CO2 do I emit?"
- "What's the latest on climate change?"
- "Where can I recycle near me?"

**Tools Used**:
- `calculate_carbon_footprint` - Real carbon data
- `search_environmental_data` - Current environmental information

---

### 2. DO: Enable Actions Users Want to Take
**Principle**: The app should let users take action on their sustainability goals, not just answer questions.

**What Changed**:
- Tool: `get_sustainability_recommendations` (renamed from `get_sustainability_recommendations` with better description)
- System prompt now includes action-oriented language
- Added explicit guidance on actionable output formats

**Examples**:
- "How can I reduce my carbon footprint?"
- "What's the best way to commute?"
- "How do I go solar?"

**Tools Used**:
- `get_sustainability_recommendations` - Specific action steps
- `convert_units_with_context` - Help users understand metrics in familiar terms

---

### 3. SHOW: Present Data in Better Ways
**Principle**: A structured UI with numbers and context is more actionable than text alone.

**What Changed**:
- Tool descriptions now emphasize structured output (ID, fields, context)
- System prompt includes: "Format numerical results clearly with context"
- UI improved to highlight metrics and comparisons
- Examples show breakdown + context format

**Examples**:
- Carbon breakdown by category (transport/flight/energy)
- "That's equivalent to X miles of driving"
- Comparison with baselines

**Implementation**:
```python
{
    "calculation_type": "transportation",
    "carbon_pounds": 7.84,
    "carbon_kg": 3.56,
    "description": "Transportation carbon footprint: 7.84 lbs CO2",
    "breakdown": {"transportation": 7.84},
    "status": "success"
}
```

---

## üîÑ Key Changes to Implementation

### Tool Naming & Descriptions

**BEFORE**:
```python
"get_carbon_footprint_calculation": {
    "description": "Calculate carbon footprint from transportation, flight, or 
                  home energy usage. Provides structured environmental impact data 
                  that ChatGPT normally cannot access."
}
```

**AFTER**:
```python
"calculate_carbon_footprint": {
    "description": "Calculate carbon emissions from transportation, flights, or 
                  home energy. Returns structured CO2 impact in multiple units. 
                  Use this when users ask about their environmental impact 
                  from specific activities."
}
```

**Why**: Clearer, shorter, includes usage guidance for the model.

---

### System Prompt Enhancement

**BEFORE**: Generic sustainability assistant description

**AFTER**: Explicit framework for decision-making
```
What makes you valuable:
1. KNOW: You access real-time carbon calculations, environmental data, and resources
2. DO: You provide personalized, actionable recommendations
3. SHOW: You present environmental data in clear, structured formats

When to use tools:
- Carbon questions: use calculate_carbon_footprint
- "How can I reduce?" questions: use get_sustainability_recommendations
- "Where do I..." questions: use search_environmental_data
- Unit questions: use convert_units_with_context
```

**Why**: Helps the model make better tool-selection decisions.

---

### User Interface Improvements

**Value Proposition Copy**:
```
BEFORE: "This OpenAI-powered assistant provides:"
AFTER: "Unlike base ChatGPT alone, EcoAgent provides:"
```

**Why**: Emphasizes *why* the app adds value vs. ChatGPT alone.

**Capability Organization**:
```
BEFORE: Generic bullets
AFTER: 
  1Ô∏è‚É£ NEW THINGS TO KNOW
  2Ô∏è‚É£ NEW THINGS TO DO
  3Ô∏è‚É£ BETTER WAYS TO SHOW
```

**Why**: Uses OpenAI's framework to help users immediately understand value.

---

## ‚úÖ OpenAI's Checklist - EcoAgent Status

### 1. New Powers ‚úÖ
- **Does your app clearly give ChatGPT new things to know, do, or show?**
  - ‚úÖ YES - KNOW (carbon data), DO (recommendations), SHOW (structured formats)
- **Would users notice if it stopped working?**
  - ‚úÖ YES - Loses accurate carbon calculations and personalized recommendations

### 2. Focused Surface ‚úÖ
- **Have you picked a small set of capabilities instead of cloning your entire product?**
  - ‚úÖ YES - 4 core tools, not 13 from the MCP server
  - ‚úÖ Intentionally narrow scope (sustainability focus, not all EcoAgent features)
- **Are they clearly scoped to real jobs-to-be-done?**
  - ‚úÖ YES - "Help me reduce my environmental impact" is the primary job

**Jobs-to-Be-Done**:
1. Understand my carbon footprint (KNOW)
2. Reduce my environmental impact (DO)
3. Find local sustainability resources (KNOW)
4. Understand sustainability terms (SHOW)

### 3. First Interaction ‚úÖ
- **Does your app handle both vague and specific prompts gracefully?**
  - ‚úÖ YES - System prompt handles both with examples
- **Can a new user understand your role from the first response?**
  - ‚úÖ YES - UI clearly states "Calculate environmental impact. Get recommendations."
- **Do they see value on the first turn?**
  - ‚úÖ YES - Examples and quick-start suggestions

### 4. Model-Friendliness ‚úÖ
- **Are actions and parameters clear and unambiguous?**
  - ‚úÖ YES - Tool names are verbs, parameters are explicit enums
- **Are outputs structured and consistent?**
  - ‚úÖ YES - All responses follow standard format with `status`, `description`, structured data

**Example Structure**:
```python
{
    "status": "success",
    "description": "...",
    "[key_data]": ...,
    "breakdown": {...},
}
```

### 5. Evaluation ‚úÖ
- **Do you have a test set with positive, negative, and edge cases?**
  - ‚úÖ YES - Example questions cover vague, specific, and edge cases
- **Do you have some notion of win rate?**
  - ‚úÖ In-progress: Need to track user satisfaction metrics

### 6. Ecosystem Fit ‚úÖ
- **Can other apps reasonably build on your output?**
  - ‚úÖ YES - Structured, machine-friendly output with stable field names
- **Are you comfortable being one link in a multi-app chain?**
  - ‚úÖ YES - Small, focused actions that integrate with ChatGPT ecosystem

**Chaining Example**:
```
User: "Help me plan a road trip"
  ‚Üì
ChatGPT uses map_app to plan route
  ‚Üì
ChatGPT uses EcoAgent to calculate carbon
  ‚Üì
ChatGPT uses flight_app to compare to flights
  ‚Üì
One seamless experience
```

---

## üìä Design Decisions Made

### 1. Tool Selection

**Decision**: Use 4 focused tools instead of all 13 from MCP server

**Tools Included**:
- `calculate_carbon_footprint` - Core KNOW capability
- `get_sustainability_recommendations` - Core DO capability
- `search_environmental_data` - KNOW capability (current data)
- `convert_units_with_context` - SHOW capability

**Tools Excluded**:
- Advanced calculation tools (redundant)
- Specialized tools (too narrow for ChatGPT context)

**Reason**: "If you struggle to summarize what the app does in one sentence, the model too will have a harder time understanding it."

### 2. System Prompt Structure

**Decision**: Explicit KNOW/DO/SHOW framework + tool selection logic

**Why**: Helps the model understand when to invoke which tool, following OpenAI's principle: "You're designing for two audiences: the human in the chat and the model runtime that decides when and how to call your app."

### 3. Output Format

**Decision**: Structured JSON with `status`, `description`, and data fields

**Why**: 
- Predictable for model to parse
- Allows user-facing description + machine-friendly data
- Stable field names for chaining with other tools
- Makes errors explicit (`"status": "error"`)

### 4. First Interaction

**Decision**: Show immediate value with examples and clear value prop

**Why**: OpenAI guideline: "If they have to answer five questions before seeing anything useful, many will simply stop."

---

## üéì OpenAI Best Practices Applied

### Principle 1: Focus on Jobs-to-Be-Done
‚úÖ **Applied**: System prompt states clear job ("Help users understand and reduce their environmental impact")

### Principle 2: Keep Surface Area Small
‚úÖ **Applied**: 4 focused tools, not 13. Each maps directly to user intent.

### Principle 3: Design for the Model
‚úÖ **Applied**: 
- Clear tool descriptions with usage guidance
- Explicit when/how to invoke each tool
- Structured outputs the model can parse

### Principle 4: Privacy by Design
‚úÖ **Applied**: 
- Only collect minimal required data
- Structured output (avoid "blob" parameters)
- No unnecessary internal details exposed

### Principle 5: Ecosystem Ready
‚úÖ **Applied**: 
- Small, composable actions
- Stable output formats
- Handles being one tool among many

### Principle 6: Value Clarity
‚úÖ **Applied**: 
- UI emphasizes "UNLIKE ChatGPT ALONE..."
- KNOW/DO/SHOW framework visible
- Examples show clear scenarios

---

## üìà Metrics to Track

Once live, monitor:

1. **Usage**: Which tools are called most often?
2. **Success**: What % of requests result in successful tool execution?
3. **User Satisfaction**: 
   - Do users see value immediately?
   - Are they coming back?
   - Are they sharing it?
4. **Win Rate**: Compared to base ChatGPT, do our responses solve problems better?
5. **Ecosystem**: How often is output used by other tools in ChatGPT?

---

## üöÄ Next Steps

### Before Going Live
1. Test with edge cases (vague intent, missing parameters)
2. Verify all tools return properly structured output
3. Test system prompt's tool-selection guidance
4. Get feedback from first users on value clarity

### Post-Launch Optimization
1. Monitor which tools get called
2. Iterate on system prompt based on model behavior
3. Add/remove capabilities based on user requests
4. Track real-world impact (users' carbon reductions)

### Future Enhancements
1. Add "context engineering" to system prompt (more advanced agent behavior)
2. Integrate with MCP server for richer capabilities
3. Add structured response cards (for SHOW value)
4. Build leaderboards (gamification)

---

## üìö Key Takeaway

EcoAgent's ChatGPT integration is now designed as a **focused, composable toolkit** rather than a "mini version of the product."

**Before**: Try to do everything  
**After**: Do 3 things exceptionally well (KNOW/DO/SHOW)

This approach makes the app:
- ‚úÖ Easier for the model to understand and use
- ‚úÖ More useful in real conversations
- ‚úÖ Better positioned for ecosystem integration
- ‚úÖ More likely to provide real value to users

---

## üîó References

- **Official Guide**: https://developers.openai.com/blog/what-makes-a-great-chatgpt-app
- **Apps SDK**: https://developers.openai.com/apps-sdk
- **Example Projects**: https://github.com/openai/openai-apps-sdk-examples
- **Community**: https://community.openai.com/c/chatgpt-apps-sdk/

---

**Status**: Fully aligned with OpenAI best practices  
**Last Updated**: November 26, 2025  
**Next Review**: After first user feedback

